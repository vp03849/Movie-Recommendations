# -*- coding: utf-8 -*-
"""Movie Recommendation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jp3Q2W-UZw11RUMTwFM4DzwCv2ecEFZi

**Installing the module 'Kaggle'**
"""

!pip install kaggle

"""**Uploading the JSON File**"""

from google.colab import files
files.upload()

"""**Creates a Directory and Uploads the JSON file to that path**"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""**Linking the Data File to the Colab**"""

!kaggle datasets download -d tmdb/tmdb-movie-metadata

"""**Listing the Files in the Path**"""

!ls

"""**Unzipping the Zipped File**"""

!unzip tmdb-movie-metadata.zip

"""**Importing the Regular Modules and Reading the File**"""

import pandas as pd
import numpy as np

df1 = pd.read_csv("tmdb_5000_credits.csv")
df2 = pd.read_csv("tmdb_5000_movies.csv")

"""**Listing the Top 5 Rows in 'df1'**"""

df1.head()

"""**Listing the Top 5 Rows in 'df2'**"""

df2.head()

"""**Merging the Datasets**"""

df1.columns = ["id" , "title" , "cast" , "crew"]
df2 = df2.merge(df1 , on = "id")

"""**Demographic Filtering**"""

c = df2["vote_average"].mean()
print(c)

m = df2["vote_count"].quantile(0.9)
print(m)

q_movies = df2.copy().loc[df2['vote_count'] >= m]
print(q_movies.shape)

def rating(x , m = m , c = c) :
  v = x["vote_count"]
  r = x["vote_average"]

  return ((v/(v+m))*r)+((m/(v+m))*c)

q_movies["score"]  = q_movies.apply(rating , axis = 1)

q_movies = q_movies.sort_values("score" , ascending = False)
q_movies.head(10)

q_movies[['title_x', 'vote_count', 'vote_average', 'score']].head(10)

import plotly.express as px

fig = px.bar((q_movies.head(10).sort_values("score" , ascending = True)) , x = "score" , y = 'title_x' , orientation = "h")
fig.show()

"""**Content Based Filtering**"""

from ast import literal_eval

features = ["cast" , "crew" , "keywords" , "genres"]

for feature in features :
  df2[feature] = df2[feature].apply(literal_eval)

df2.dtypes

def get_director(x):
    for i in x:
        if i['job'] == 'Director':
            return i['name']
    return np.nan

df2['director'] = df2['crew'].apply(get_director)

def get_list(x):
    if isinstance(x, list):
        names = [i['name'] for i in x]
        return names
    return []

features = ['cast', 'keywords', 'genres']
for feature in features:
    df2[feature] = df2[feature].apply(get_list)

df2[['original_title', 'cast', 'director', 'keywords', 'genres']].head(3)

def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

features = ['cast', 'keywords', 'director', 'genres']
for feature in features:
    df2[feature] = df2[feature].apply(clean_data)

def create_soup(x):
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])
df2['soup'] = df2.apply(create_soup, axis=1)

from sklearn.feature_extraction.text import CountVectorizer
count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(df2['soup'])

from sklearn.metrics.pairwise import cosine_similarity
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

df2 = df2.reset_index()
indices = pd.Series(df2.index, index=df2['original_title'])

def get_recommendations(title, cosine_sim):
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return df2['original_title'].iloc[movie_indices]

get_recommendations('Avatar', cosine_sim2)